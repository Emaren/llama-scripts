ğŸ§© LLAMA DEV SNAPSHOT â€” v2025-07-25
ğŸ“Œ Recent Highlights
âœ… Clean venv rebuild (3.11.9)

âœ… .envrc + pyenv auto-activation

âœ… LLAMA_SNAPSHOT.md symlinked

ğŸ§¼ GitHub secret cleanup

ğŸªŸ Tile polling + Next.js metadata bug resolved

âœ… STACK STATUS (LIVE)
Layer	Port	Component	Tech / Status
ğŸ¯ AoE2HD App	â€”	Frontend	Next.js âœ… (Flutter live)
ğŸ¯ AoE2HD API	8003	Betting backend	FastAPI âœ…
ğŸ§  Metrics API	8005	llama-api	FastAPI âœ…
ğŸ§© Chat Agent API	8006	llama-chat-api	FastAPI âœ… (SSE patched)
ğŸ’¬ Chat UI	3006	llama-chat-app	Next.js âœ… (streams OK)
ğŸ“Š Dashboard UI	3005	llama-dashboard	Next.js âœ… (metrics flow)
ğŸ§  Ollama LLM	â€”	LLaMA 3 8b Q4_K_M	âœ… Local inference
ğŸ­ OpenAI Agent	â€”	Agent4oMP	âœ… Prompt-Mgmt injected

ğŸ§° PM2 SERVICES SNAPSHOT
Name	Port(s)	Tech
token_tap_app	3007	Next.js
token_tap_api	8007	FastAPI
redline-legal-app	3004	Next.js
redline-legal-api	8004	FastAPI
explorer-prod	4173	Vite
wolo-prod	26656/26657	Cosmos SDK

ğŸ§© VENV INFRASTRUCTURE SNAPSHOT â€” v2025-07-25
1ï¸âƒ£ Legacy (Python 3.11.9)
ğŸ“ Repo	ğŸ§ª Env Name	Python Ver	Env Type	Auto-activation
llama-chat-api	api311	3.11.9	pyenv-virtualenv	layout pyenv âœ…
llama-chat-app	app311	3.11.9	pyenv-virtualenv	layout pyenv âœ…
llama-api	llamaapi311	3.11.9	pyenv-virtualenv	layout pyenv âœ…
llama-dashboard	dashboard311	3.11.9	pyenv-virtualenv	layout pyenv âœ…

2ï¸âƒ£ Auto-bootstrapped via direnv-bootstrap-all.sh (Python 3.12.3)
ğŸ“ Repo	ğŸ§ª Env Name
aoe2hd-parsing	aoe2hdparsing312
api-prod	apiprod312
api-prodf	apiprodf312
api-prodn	apiprodn312
api-staging	apistaging312
llama-api	llamaapi312
llama-backend	llamabackend312
llama-chat-api	llamachatapi312
llama-chat-app	llamachatapp312
llama	llama312
token_tap_api	tokentapapi312

3ï¸âƒ£ Per-repo via direnv-bootstrap.sh (Python 3.13)
ğŸ“ Repo	Venv Path
llama-scripts	.direnv/python-3.13
(symlinked helper)	for any project you cd into

ğŸ§  Activated by: direnv (.envrc) + either .python-version or .direnv/python-<VER>
ğŸ§© Shims route to: ~/.pyenv/shims/python

ğŸª SYMLINKS
File	Linked In	Notes
LLAMA_SNAPSHOT.md	llama-chat-api, llama-chat-app	âœ… Global visibility
direnv-bootstrap.sh	every project (via symlink)	âœ… DRY propagation
direnv-bootstrap-all.sh	top-level ~/projects	âœ… Bulk bootstrap

ğŸš INFRA & DEV HYGIENE
âœ… PM2 frontend: start-llama.sh

âœ… PM2 backend: venv/bin/python -m uvicorn â€¦

âœ… Auto-activation: .envrc + pyenv local 3.11.9

âœ… Python: clean 3.11.9 build

âœ… Alias fix: unalias python && exec zsh

âœ… Git hygiene: ignores venv/, .env, .idea/, .pyc

âœ… iOS testing via *.ngrok-free.app

ğŸ§ª LAUNCH SCRIPTS
Script	Status	Notes
start-chatdev.sh	âœ…	Tmux, clean venv start, envs autoload
start-dashdev.sh	ğŸ”œ	Align structure & hygiene

ğŸ”Œ CHAT SYSTEM
Framework: React 19.1 + Next.js 15.3.4 + Tailwind âœ…

Markdown: via ReactMarkdown âœ…

Streaming: streamChat() âœ…

Key Routes: /api/chat/send, /chat/messages/{agent}, /responses âœ…

ğŸ“Š DASHBOARD SYSTEM
Frontend: Next.js 15.3.4 @ :3005

Backend: FastAPI @ :8005

Live Endpoints: /stats/tokens, /system-vitals, /agents/health

Auto-refresh: In progress

ğŸ§  OLLAMA LLM (LOCAL)
Model: llama3:8b-instruct-q4_K_M

âœ… Persona injection + streaming

âœ… Memory: ./memory/{agent}.json (12K cap)

âš ï¸ keep_alive: false patch to avoid stale containers

âš ï¸ BUG FIXES
Issue	Resolution
âŒ Stream reply invisible	logRef[idx] = {â€¦} + flushSync()
âŒ Token tile stale	refetchInterval + invalidate()
âŒ SSE fallback	<prompt:â€¦> + client.responses

ğŸ§± NEXT.JS & ENV FIXES
âœ… .env secrets removed & rotated (via BFG)

âœ… Hydration: wrapped in <ClientProviders>

ğŸ§  MEMORY SYSTEM STATUS
Feature	Status	Notes
Persistent JSON	âœ…	Per-agent memory
GPT Pre-injection	âœ…	Injected at start
Tagging	ğŸŸ¡	Inline scoped tags
FAISS search	ğŸŸ¡	Scaffolded
Scoped filters	ğŸŸ¡	Token-fit filtering
GPT summaries	ğŸŸ¡	Auto-chunking in dev
Pruning	ğŸ”œ	Next pass
Manual validation	âœ…	All agents validated

ğŸ”¬ MEMORY ROADMAP â€” Q3 2025
ğŸ”– Tagging + ğŸ§  Embeddings

ğŸ“ Scoped filters

ğŸ’¬ GPT summaries

ğŸ§¹ Pruning

ğŸ§¬ Mutation / Replay

ğŸ“‚ Next: vector_memory.py

ğŸš VENV STATUS
Project	Activated Via
llama-chat-api	âœ… source venv/bin/activate
llama-chat-app	âœ… .envrc + direnv
llama-dashboard	âœ… .envrc + direnv
llama-api	âœ… .envrc + direnv

ğŸ“‹ FEATURE SNAPSHOT
âœ… SSE backend

âœ… Markdown rendering

âœ… Agent-based memory

âœ… Stream isolation per agent

âš ï¸ Prompt-Mgmt SSE fix pending

ğŸ”„ Token tile auto-refresh pending

ğŸ“± MOBILE / NGROK
âŒ iOS Safari fails on localhost

âœ… Use:

NEXT_PUBLIC_API_BASE=https://<your-subdomain>.ngrok-free.app